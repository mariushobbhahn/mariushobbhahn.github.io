---
layout:     post
title:      "A history of changing my view"
subtitle:   "A list of beliefs that I changed over the last couple of years"
date:       2019-12-21 20:28:00
author:     "Marius Hobbhahn"
# header-img: "img/Marius2.jpg"
category:   opinion
tags:       [discourse, rationality]
---

## **What is this post about?** 

I have multiple times experienced the following situation: "A friend of me and I had a discussion where we disagreed on something. The discussion is not resolved at this point in time. Some time later (maybe a couple of months or even years) we discuss the same issue again. Suddenly we both agree but claim not to have changed our opinions. I genuinely believe not to have changed my opinion and they genuinely claim to not have changed theirs." Somewhere in this process either of us has to have changed their opinions. I think this phenomenon is related to humans desire that their beliefs "follow a red line" over time i.e. we want our convictions to be consistent with each other and we don't like to be wrong. Accepting that we have been wrong in the past implies "admitting" that we have been wrong in the past. Since we prefer the warm feeling of being right over the sad truth that we have been wrong our brain mostly pretends that we have always held the opinion that we currently hold. Obviously my description is a simplification and this is not true in all cases and there exist exceptions, etc. TODO: link the actual fallacy. I believe that this fallacy has bad effects because it prevents us from learning from our mistakes effectively. I think we should therefore embrace the fact that we have been wrong in the past and are less wrong now. In this post I list a couple of issues on which I changed my mind and discuss why that happened. I try to only take views on which I had an explicit opinion which I then updated and not just new things that I learned even though the boarder is somewhat vague. If you think that my current beliefs are inaccurate or wrong I would be happy to discuss them with you. When reading this text, keep in mind that I have not written these opinions down explicitly at earlier points so they are a reconstruction of my memory. 

## People 

#### Importance of social relations

My opinion about the importance of the quantity and quality of social relations actually changed quite drastically over time. As a teenager I was of the impression that it is very important to have many friends and be liked by everyone. After starting university I realized that I actually did not have strong reasons to keep most of my social relationships because of diverging interests. My new belief was 
that most friendships are not worth much since you lose them once you change location, job, etc. I have softened this view quite a bit to arrive at my current position where I think that it is important to have a core group of friends that you can trust and plan to keep in contact with even when you move location. I still believe that there is no reason to try and please everyone. 

#### Polygamie/Polyamorie

During my undergraduate I was very libertarian in my belief about sexual relationships (more in theory than in practice though). I thought that the most important thing in relationships was to be as free as possible, i.e. to do whatever you want with whomever you want as long as this partner consents. I saw every form of commitment as a restriction in my freedom and therefore rejected it. I now believe that commitment is an important and necessary thing for a relationship to work. I think I changed this view because I undervalued the benefits of long-term stable relationships. I kept my view on Polyamorie and still believe that people can have more than one relationship at a time. 

#### Signalling

I always had the intuition that communication was not only about transmitting information but also signalling status, intentions, etc. I think I firstly realized this after going to the theater. After the play I wanted to discuss the plot with some members of the group and its possible interpretations. Some of the people had not even listened very carefully or were playing around with their smartphones during the play. However, they were very keen on telling their friends and family that they have been to the theater. They wanted to signal that they are a very intellectual person and gain the social capital attached to it. I think this can also be seen on Facebook or Instagramm. While some part of "sharing with your friends" is surely information based, i.e. you want them to know that you are on holidays, another part is used to signal that you are able to signal some positive attribute, i.e. that you are able to afford holidays, that you have a happy family, etc. Thinking about communication not only as transmitting information but also as a means to communicate status and intentions can tell you a lot about the person you are talking to. "Reading between the lines" and asking what kind of attributes they want to be associated with often tells you more about the person than what they are actually saying. 
My opinion on signalling has been influence strongly be reading "The Elephant in the Brain" TODO:link and an episode of rationally speaking TODO:link. I want to emphazise, that realizing that something is signalling does not make it worthless. This blog is to some extend me signalling but I hope it still contains useful information. 

#### I am less smart than I thought

During most of my school career I had a very easy time even with low effort. When I was ten years old I did an IQ test with my good friend Samuel. I did not really understand what the results ment, just that we were "pretty smart". The social feedback that I received during most of my school career also was that either I was the smartest person in the room or that Samuel and I shared the top two spots when we did something together. This selfperception mixed with the hormonal coctail of an 18 year old made me overvalue my intelligence. I think I have come to the sad conclusion that I am less smart than I thought I was mostly due to the following reasons.
1. Meeting a ton of people who are clearly smarter than I am. My social bubbles are Effective Altruism, Debating and University. All of those are (self-)selective for intelligent people and after meeting some professors, students, debaters or EAs there was just no way denying or rationalizing the huge gap in intelligence that was between me and a more intelligent person. It was just obvious that they were smarter. 
2. A better understanding of probabilities. I think that the IQ test is a relatively accurate representation of someones intelligence. Of course there are some problems with the selection of questions discriminating against certain groups or some people preparing for the test and thereby feeling really smart and skewing the curve, but as a broad approximation it works. After having understood that the IQ number that you get is just a representation for the percentile in which you fall I knew that there were 100-X percent of society that have better results in the test than I do. (I retook the test when I was 20 and had the exact same result as when I was 10, that gives me more reason to believe it measures something reasonable)
3. A better understanding of conditional probabilities. The IQ test tells you your intelligence in relation to the entire society, i.e. you are in the X-th percentile. However, most of the time our social circles are highly selective. After reading up on the average IQ that people in a Bachelors programm, Masters programm, PhD or Post-doc have, I had to accept that with high probability I will not only be not the smartest person in the room but in fact be below the average IQ of that select group of people. 

#### Difference between men and women are not only socially constructed

After reading parts of Judith Butler and other feminist theory I was pretty convinced that the differences between men and women were entirely socially constructed, i.e. the associations between blue and male and pink and female or the distroportionally high amount of women in social jobs and men in the tech sector. While I think that the association between color and gender is entirely socially constructed some other effects cannot be explained only using socialisation. To explain some of the effects, I think, we have to consider at least a second variable: Hormones. I updated my view because
1. I underestimated the effects of **hormones**. I was mostly swayed by first seeing the effect that the pill had on one person and their emotional status and then doing some research on the effects of hormones on your preferences and behaviour. 
2. The **"Sweden paradox"**: Paradoxically, the countries that provide the highest equality of opportunity yield less equality of outcome for jobs and gender. That means that even though there are no legal barriers and all options are open independent of the gender, there are more men in STEM and more women in social jobs. Technically, this could still be explained by social factors alone - maybe there is a stronger class ceiling in the nordic countries or there are different social norms, but it is definitely harder for such a theory to explain the inverse correlation between equality of opportunity and equality of outcome seen in the nordic countries. For further information check out <a href='http://www.epicenternetwork.eu/blog/the-swedish-gender-equality-paradox/'>this article</a> or <a href='https://www.researchgate.net/publication/323197652_The_Gender-Equality_Paradox_in_Science_Technology_Engineering_and_Mathematics_Education'>an actual paper</a>.
3. **Evolution**: From an evolutionary standpoint it is plausible that different genders fulfilled different roles. Since cultural change is faster than genetic encodings it is plausible that some of the genes still lead to different preferences depending on the existence of a Y chromosome. 

To be crystal clear - if my observation is true this does not justify oppressing women in any way or restricting their choices. Just because preferences might ON AVERAGE be different does not mean that many individual women or men want something very different. However, I personally think that this could still have polical consequences. For example, it might be rational for feminism to lobby for the improvement (rights, salary, parental leave, etc.) of traditionally female roles instead of trying to seek equal representation in traditionally male roles. I have not yet thought sufficiently about these consequences to definitely say that would be a good idea but it is a thought that seems to be underexplored - at least in the feminist discussions within my social bubble.

#### I undervalued experience 

I originally thought that experience is overvalued and to solve a problem it would be best to argue from first principles and use intelligent reasoning. I though that a lot of experience was folk wisdom and would not actually stand up to scientific scrutiny. I still assumed that on average more experience would imply a higher proficiency within a certain field but I thought more experience could easily be outweighed by intelligence. So, for example, I would have assumed that an average intelligent person with 3000 hours of chess experience would easily be beaten by a significantly more intelligent person with 1000 hours of chess play. While I do not have any data on chess I would now estimate that these two people would either be equally good or the more experienced person would win more often. I think my opinion change due to a factor that can be summarized as **the gut feeling**. I originally thought that the majority of the knowledge we have about a certain subject was easily accessible and would be factored in during decision making. However, after finding out that many professional chess or Go player often base their decisions more on feeling than logic and many experts have problems justifying their predictions with logic even when they are correct, I had to update my model of decision making. I now think it is to a very large extend latent knowledge that controls our decision making. It is the combination of the thousands of situations that an expert has assessed before and the many times they have been wrong that lead them to have a more calibrated model of a situation. I was aware of the existance of the subconscious parts of our decision making I merely changed my opinion on how much of an influence they have. The practical consequence of this is pretty simple: I am now more likely to trust a person that has a lot of experience with the assessment of a situation even if they cannot explain it. Merely the fact that they "have a bad feeling about it" now has a lot of weight for my decision. I would now rather try to get to the bottom of what exactly produced this "bad feeling" rather than discarding it as "just a feeling" and searching for a more logical explanation via first principles. Often, the logical explanation is found after the source of the "bad feeling" is identified. 

#### Rationality and emotions are not mutually exclusive

Until coming in contact with Effective Altruism and thereby the rationality community my views on rationality were mostly shaped by conventional norms and pop culture. I thought, for example, that Sheldon Cooper from the big bang theory was a rational person due to his cold and distant attitude. However, there are a lot of Sheldons characteristics and behaviours that are terribly irrational. For example, he is very reluctant to accept that someone else is correct even in face of overwhelming evidence. It was this cultural representation that led me to believe that emotions and rationality are mutually exclusive and I strove to repress or ignore them. 
Now I think that there are two aspects to rationality. First, rationality implies that you search for the most effective ways to reach your goals. Second, rationality implies that you want to have the most accurate representation of reality, i.e. you want to remove biases that cloud your perception of the world or your decision making and you want to make informed decisions based on that knowledge. These definitions are not directly mutually exclusive to emotions. Some emotions might stop you from making decisions that maximize your goals and should therefore be accounted for. I believe, for example, that grief and jealousy are pretty useless emotions and try to make a conscious effort to overwrite them but other emotions might very well be an integral part of your decision. Happiness or love might even be the very goal you are trying to achieve with rational decision making. 
Unfortunately, the cultural wisdom of "rationality == no emotions" is very sticky and pernicious and it will take some time for it to vanish. I think it is actually pretty important to clear up this confusion because it leads to bad situations. Some people are mean to their partners in relationships under the guise of rationality because signalling that you are especially emotionless can be pretty hard for your partner (I was definitely guilty of that in the past). It also leads to some people rejecting important lessons from rationality (i.e. how biases cloud our decisions) because they think becoming more rational means giving up their emotions. 

## Ethics

#### My perspective on Effective Altruism (EA)

When I heard of EA for the first time I was immediately drawn into the movement. It just seemed so obvious to me: There are millions of people suffering right now and there are effective tools to help them. I immediately wanted to start and do something. The urge to act was enormous. Since I had just started my undergrad the only things that I could do were organizing meetings, go to conferences, focus on my studies, become vegan/vegetarian and donate parts of the little money I had. I was aware of the fact that these contributions didn't matter that much, I could not donate a lot, the local meet-up grew slower than I had hoped and one person being vegetarian or vegan only alleviates a very small amount of suffering. So my best shot was to focus on my studies, get into a good position to either have a lot of positive effects through my work or donate a lot to effective charities. The fact that this seemed like the only reasonable shot at having a high impact really put a lot of pressure on me and every bad grade felt like I was stabbing a future child by not being able to donate as much. This is obviously neither healthy nor helpful. I thought about this pressure and as already described in my EA article TODO:link I changed my perspective to preserve my mental health. The second way in which my view on EA changed is on the immediacy of help. I think this urge to help immediately when you see suffering is very strong and I therefore wanted to donate NOW or to rush through your studies to get a job ASAP. However, this strategy is not long-term optimal. EA is still in its infancy, historically speaking, and a lot of assessments might be updated quickly. Just take the shift in stance that 80K (TODO:LINK) has made on earning to give. After my Bachelor's I could have rushed to become a trader and donate most of my earnings only to find out that this was ineffective compared to working on some projects directly or be an AI safety researcher. I guess my view on career choice can now be summarized by the following ideas:
1. Choose something that you are comfortable doing now but also will likely be comfortable doing in the future 
2. If you don't know what you want to do try around a lot. Go to EA conferences, speak to a lot of people, read 80K, etc.
3. If you realize your current choice does not suit you don't hesitate to switch even if it feels like "having wasted all that time"
4. Do not optimize for immediate impact at the cost of larger long-term impacts. A high government position might be very impactful even if you "had no impact" until reaching that position

#### Short-term vs. long-term Effective Altruism

One of the EA internal debates is on a dimension of short-term vs. long-term effects. I would say I did not have a strong opinion on it in the beginning but was leaning slightly towards short-termism because of the urge to act now as described in the paragraph above, the high uncertainty attached to some of the long-term scenarios and a certain fear of failure (e.g. what if I became a AI safety expert but fail to contribute anything meaningful). By now my view is leaning much stronger towards the long-term end of the spectrum. This is partly because the community as a whole shifted their stance a bit, partly because I am less risk averse now (and can therefore more easily accept to maximize expected value) but most importantly due to a talk given my Stefan Torges (see his blog TODO:link) and a conversation following it. In the end it is still a simple back-of-the-envelope calculation but was still able to convince me sufficiently to update my view. Let's assume that the trajectory of human civilization is not yet near its end and will go on for 100k years at least. Further assume that the sigmoidal shape of describing population growth is broadly correct and we settle at 10 billion humans on the planet. Let's say there is a 1 percent chance of a global pandemic (like CoviD-19), a 0.1 percent chance of a world war and a 1 percent chance of a very bad AGI scenario per year. This implies that in 100k years of civilization there will be 1k pandemics, 100 world wars and 1k very bad AGI scenarios. Let's further say that around half of the global population would be affected by the pandemic in a significant way and everyone by the world wars and the AGI scenario. If we assume that the suffering that is created through these scenarios is equivalent to the suffering of having malaria, then reducing the number of pandemics from 100 to 99 means that 5 billion people in the future do not have to suffer. That would on average be 50k people per year. Using GiveWells estimate of 6000 Dollars to save a live from Malaria we would be at 300 million dollars per year. That is an amount that I am very unlikely to earn or even come close to over the entirety of my life. The same estimates can be made for the world war scenarios, the bad AGI trajectory and other long-term problems such as climate change and yield similarly astronomical amounts of suffering. The chosen numbers are obviously guesstimates and might be very wrong, but even if they are wrong by a couple of magnitudes the argument is still pretty strong. 
Before Stefans talk I already knew that "the future is long, there are many people, large impact, blablabla". I still needed to crunch the numbers to get an intuitive understanding for the incredible magntitude of these effects and thereby convince myself to such a degree that the felt uncertainty attached to the long-term perspective becomes pretty irrelevant. 

#### Happiness/Suffering is not the only valid metric

I think there are two different Happiness related opinions I updated. 
- Happiness includes much more than the short emotional ups and downs plus diseases. Some harder to measure mental states such as contempt/satisfaction/tranquility/depression must be factored in very strongly. I never denied the existence of the influence of these other factors I merely updated the degree to which they influence the overall happiness of an individual. While my original estimate was around 80:20 for short-term emotions it is not something like 70:30 in favor of other mental states. The reason for this update was mostly due to personal experiences. When I explicitely compare a good day in a rather depressive phase of my life to a bad day in a contempt phase of my life I prefer the latter. This is hard to explain with the original numbers. To illustrate consider the following figure.

TODO image: two sine-curves with differen amplitudes.

- Non-happiness/suffering focused metrics have more validity for me now. 

TODO: find good example


## Science

#### Science is less accurate than I thought

My pre-undergrad understanding of science was terribly naive. I assumed that scientists tested hypotheses by running experiments that then yield easily interpretable results that can then be seen as "truth". What I completely underestimated was the complexity of the scientific apparatus, i.e. fact that science is conducted by people which have to follow certain rules that are made by people who are not necessarily scientists themselves, etc. There are some reasons that lead me to believe that science produced a lot of results that are either overblown or just wrong.
1. Incentives: p-hacking, status > scientific truth
2. Social dynamics
3. Statistics

#### Machine Learning and AI is powerful in different ways than I thought


#### Neuroscience knows merely the basics if at all



## Economy


#### I underappreciated markets



#### FCC chairman ajit pai



#### Block-Chain technology


#### The solution to housing is not rent-control


#### ***One last note***

If you have any feedback regarding anything (i.e. layout or opinions) please tell me in a constructive manner via your preferred means of communication.



