---
layout:     post
title:      "How much free speech do we need?"
subtitle:   "What are the rules for good discourse?"
date:       2020-08-15 20:28:00
author:     "Marius Hobbhahn"
header-img: "img/TODO"
category:   opinion
---

## **What is this post about?**

I have thought a lot about free speech lately. The events that influenced my thinking most were a long discussion/twitter war surrounding Yann LeCun about bias in Machine Learning that ultimately lead to a <a href='https://twitter.com/ylecun/status/1277372578231996424'>reduced Twitter presence</a> by him (click <a href='https://www.youtube.com/watch?v=n1SXlK5rhR8'>here</a> for an informative but biased summary) and the cancellation of J.K. Rowling due to her controversial <a href='https://www.jkrowling.com/opinions/j-k-rowling-writes-about-her-reasons-for-speaking-out-on-sex-and-gender-issues/'>stance on transgender issues</a>. In the case of Yann LeCun, I was mostly thinking about how the discourse could have been lead in a more productive and less toxic manner. I think that some of the criticisms were fair and others were not but the way in which the discourse was held was very suboptimal and Yann LeCun reducing his Twitter presence is a loss for the ML community. In the case of J.K. Rowling, I was faced with different problems. While I agree with her on some problematic tendencies within parts of current online culture (e.g. the level of toxicity) I disagree with much of the content of her essay. She claims, for example, that ''studies have consistently shown that between 60-90% of gender dysphoric teens will grow out of their dysphoria''. There is a multitude of problems with these studies such as very small sample sizes, potentially biased researchers, potential confounders, and the ignorance of other studies on the same issues and I, therefore, think that this statement is at least misleading and should have been presented with less certainty and given a more scientific contextualization. She also claims that "We’re living through the most misogynistic period I’ve experienced." which could be a statement about her lived experiences or a statement about online culture but feels more like a grander claim about society at large. I find this a bit confusing given that most indicators of gender equality have improved over the last 30 years (see e.g. the <a href='https://www.imf.org/external/datamapper/GII_TC@GD/gbtier_1/gbtier_2/gb_othersource'>Gender Inequality Index</a>). There are multiple other statements and sentiments that are wrong or misleading to the best of my current knowledge but the overarching questions that I asked myself were: a) How should you respond to someone who has significantly more reach and your corrections are likely not noticed by most of the audience? And b) How do you stop and ideological drift after public criticism? After her cancellation, J.K. Rowling doubled down on her claims and endorsed even worse conspiracy-like claims about gender and non-binary issues.

Talking about free speech is always a bit weird for me because I don't subscribe to either of the classic ideological camps. Even though my cultural views are rather progressive I often don't like the strategy by which the goals are supposedly achieved (e.g. being very trigger happy with cancelation). On the other hand, I don't consider myself a clear free speech advocate. I think it is completely fine to deny some people a platform or to cancel a person after a long history of racist or other problematic behavior. It is additionally weird for me because my go-to strategies of evidence-based policy or science are hardly applicable to questions regarding free speech since discourse often deals with very vague and hard to quantify concepts such as productivity (as in distinguishing good from bad ideas), inclusivity or agency.

What I will attempt in this post is to find a 'sweet spot' for free speech. While I originally assumed that free speech acts on a slider and could be turned up or down like a thermostat I don't believe this anymore. I now think that free speech is NOT on the one-dimensional spectrum but rather a collection of different individual behaviors and institutional rules that each lie on a spectrum of good and bad.
In this post, I want to identify different forms of behavior and general rules that have a causal effect on the quality of discourse and weigh them according to two metrics. The first metric is the productivity of the discourse, i.e. is it able to distill good ideas from bad ones. The second is inclusivity, i.e. how likely are people to engage in the discourse, are willing to voice non-conformist opinions, or feel excluded. I also want to clarify that when there is a trade-off to be made I would prioritize productivity because it seems more important to me that a good result is found than that everyone voices their opinion. A YouTube comments section, for example, is very inclusive in the sense that everyone feel like they can comment whatever they currently think but is very unproductive since most comments are bad, non-responsive, etc.

As always, if you think I have straw manned a specific argument, misrepresented a person or view, etc. please contact me.

## How did we get to the status quo?

Before we get into questions of how discourse should be designed we have to get a clearer picture of the status quo. I think there are three trends that have changed discourse in the last couple of years that can mainly be attributed to increased digitization of discourse and a shift to online platforms like Facebook, Twitter, and YouTube.

1. **Social media and bubbles:** Social media is run by for-profit corporations. They are responsible to their shareholders and their primary interest isn't to create optimal discourse but rather to maximize view time. With view time comes more ad-revenue and this is, therefore, what the algorithms are optimized for. Throw human psychology in the mix and you will get two rather unfortunate effects: a) <a href=https://en.wikipedia.org/wiki/Confirmation_bias'>Confirmation bias</a> is a very strong human tendency to like information that confirms our previous view and dislike information that refutes or weakens them. This means that the algorithms are created to or have learned to primarily present you with information that you broadly already believe in. This means that our current views are strengthened all the time but we are rarely confronted with evidence against our beliefs. Since you read even more stuff confirming your opinion and less refuting it you are also likely to become more radical in this belief. b) To leave the comfort zone of your bubble a strong driver is needed. This often comes in the form of strong emotions such as anger and rage. Again, algorithms are designed to or have learned to create controversy to activate these strong emotions and actively promote posts that will spark a small internet war. Social media companies have been made aware of these trends and have acted to mitigate them (e.g. YouTube conspiracy theory rabbit holes are not as bad anymore) but the overall trends still exist to the largest extend. The consequences of this are clearly harmful. You either rarely interact with a view that you don't hold or when you interact you are fueled with rage ready to defend society against the barbarians from the other side.
2. **Signaling and purity tests:** Criticizing someone always has multiple components. On the one hand, you want to correct someone’s view and improve their knowledge. On the other hand, though, it is also about showing to others that you know better or that you stand on the right side of history. I think online discourse weakens the first component and emphasizes the second. If, for example, someone on Twitter says something racist there is nearly no point in writing a nuanced answer about how this could affect others and giving reasons for why they should change. The comment is too long and it will not get traction in the attention economy. Also, since you will likely not interact with that person ever again, there is no long-term benefit of your constructive engagement. Calling them a Nazi, however, will give you positive reinforcement. Since the algorithm will notify your own bubble of your valiant effort to defend the right side of history you will get their likes and attention. Additionally, you gain social capital by being purer than everyone else. Calling someone a Nazi gives you more credit than calling someone a potential racist because it shows how pure you are. If you are willing to use the word Nazi so easily you yourself must have hold yourself to high ethical standards afterall or you would risk other people calling you a hypocrite. (TODO: is this mechanism clear to a non-rationalist?). While these effects also existed before Twitter and Facebook existed, I think they were amplified through them. Online you will likely not interact with a person again and actually helping them is therefore not rewarding. In real life, you are more likely to meet them at work or school. Online you are rewarded by your own bubble but rarely notice the reactions of others. There are probably a lot of people looking at your comment and think "well that was a bit over the top. The person might be somewhat racist but calling them a Nazi is a bit drastic." However, they either don't bother to comment or are not willing to defend someone who was already labeled a Nazi. In the real world, you would often see their facial reactions, or someone might actually pull you aside later and talk to you. Purist signaling is, therefore, not as rewarding in real life. The problematic consequence of this is that criticism is not judged by whether it effectively changed someone’s mind for the better but rather by how much applause you get from your own peers. The fact that many people who are labeled as Nazis are welcomed with open arms by populist and conservative movements is not part of the consideration anymore. This argument obviously applies to the other side of the spectrum as well. Incorrectly labeling someone as a Communist will not increase your chances of persuading them.
3. **Political polarization:** Many states around the world have seen an increase in political polarization. Its reasons are manifold and overlap with points above but I still want to explore a couple in the following. I think the primary reason are the social media bubbles. If the majority of your voters are more radical and less understanding of other views than before the politicians representing them can't ever compromise. Meeting in the middle is more likely to be seen as a breach of trust and the respective politician as a traitor and compromises are therefore less likely to happen. Combine this with a broken electoral system such as the USA where it is more important to mobilize your base than to win over votes and you have a perfect recipe for a gridlock. Politicians are really in a very precarious situation here. They first have to mobilize their base by telling them how evil the other side is and then explain to them why they made a compromise with the devil. The second reason is that right-wing populist parties have been getting stronger in a lot of countries around the world. The reasons for that are manifold and include economic instability, a certain desire for identity, and a feeling of being left behind by the traditional establishment. However, they have shown much more competence than established parties when it comes to social media and online discourse. Through this, they have successfully moved the Overton window for parts of society to the right and further split society in the middle. Lastly, I think the availability of information combined with online bubbles has opened the possibility to strawman the shit out of your political opponents. Ben Shapiro choosing a young feminist that fulfills all the negative societal stereotypes (angry, uncontrolled, maybe overweight) to strawman their arguments and seemingly 'destroy' them has become the go-to characterization of feminism within the right-wing space. The left is equally guilty when it comes to this. There are dozens of people online that make a living by 'exposing' Trump voters by baiting them in dumb answers or selectively showing the most ridiculous answers. In both cases, the young feminist and the Trump supporter, are probably to a large extend victims of their socialization or brainwashed by Fox News but are portrayed as people with full agency choosing to support rather stupid positions. This implies that everyone can easily paint a scapegoat to strawman the other side. Instead of actually engaging with the arguments you can just say "look at this person and how dumb their arguments are".

## What are the implications on free speech and discourse?

After having painted a rather grim picture of reality I want to discuss what individuals and society can do to counterbalance these problematic tendencies. Given that I think these trends are rather strong the countermeasures have to be too. Since the algorithms are often explicitly designed to or have learned to exploit our emotional drives and tendencies I think it is especially important to keep them in check or install measures to counterbalance them.

### What can institutions do?

I think institutions such as governments or international bodies can mostly mitigate the harms done through filter bubbles and other problematic trends created by social media. However, the exact mechanisms through which bubbles form and their effect have not yet been fully understood and governments are often rather incompetent when it comes to technology. Therefore, we can't hope for the state to fix this one alone. Additionally, when it comes to public discourse the state is even more powerless and for good reasons. It is not only hard to restrict and control the largest part of discourse but it is also not desirable. Since it is hard to actively censor people without restricting a lot of civil liberties the state would have to create an image of fear such that people self-censor as in authoritarian regimes. This is clearly too large of a price for such a small benefit. In my opinion, the state should prosecute the worst forms of hate speech or if people incite violence but everything softer than that is up to personal responsibility.

### What does it mean for individual discourse?

The largest part of this post is therefore a collection of heuristics and rules that I think would lead to better discourse. If you think some of them don't make sense or I missed some please contact me.

1. **Check the setting:** I think the setting is a large determinant for what should be allowed to be said. In an academic setting, for example, I think nearly every hypothesis should be discussable. All participants voluntarily entered the discussion and it is sufficiently closed that it does not have larger ripple effects within society. In a more public setting, you should be more careful about the effects of your statements. I, for example, would not discuss my views on Antinatalism at the Christmas table when my cousin just had a baby. If you feel like you have to present a more radical view in a public setting I would always make sure to announce that beforehand in some way to make sure people can opt-out. If people are forced to listen to you, e.g. because you are their professor, I would also advise to be a bit more careful. If they opted in knowing what the topic is I don't see any major problems. So the two axes on which I would evaluate the setting are closed vs. public and voluntarily vs. forced.
2. **Check your reach vs. expertise ratio:** If you have high reach but talk about a topic that you have little expertise in I would be rather careful. Even if J.K. Rowling just voiced her honest opinion she still is an idol for many younger people some of which are probably questioning their identity in some way or the other. If you publish an essay about such a controversial topic you better make sure that the evidence is watertight or you flag the difference between evidence and opinion more clearly. Jürgen Klopp, the trainer of Liverpool has actually given an <a href='https://www.youtube.com/watch?v=DkIZZCbxngQ'>surprisingly good answer</a> about the problem of reach vs. expertise when he was asked about his opinion on Corona.
3. **Assume good intentions:** Even though I know the pain of feeling like you are intentionally straw manned I think it is important to assume people act in good faith and only change that opinion when people have clearly demonstrated otherwise. There are so many reasons why people might make mistakes that are not driven by bad intentions. They might misgender someone by accident. Maybe it is their first confrontation with a transgender person and they are insecure about the situation as well. Maybe they have a different cultural background and their norms around discourse differ, e.g. they think something is normal that you find rude or the other way around. Maybe they are just less knowledgable than you are. A simple question such as 'How can you feel like a man when you were born a biological woman' might not be insensitive but their first confrontation with the issue of transgender. There are many more reasons why something that looks like a bad-faith argument is actually not and we should a priori not assume it to be even if it costs us mental effort.
4. **Constructive criticism:** I think that constructive criticism is the most important of all the rules laid out in this post. For criticism to be constructive it should a) not be blame seeking but solution-oriented, b) give an explicit and achievable improvement for the other person and c) focus on flexible things such as behavior and not static traits such as character. My personal experience is both that I am way more open to criticism when it is formulated in a constructive way but also that other people have been more open-minded when I phrased it in a constructive manner.
5. **Try not to put in camps & ideologies:** I personally had many encounters where, after a couple of sentences, my brain went "Oh a Communist/Republican/Anti-vaxxer/Snob/Libertarian/Rationalist/EA/Debater/etc., here we go again" and tried to categorize them into some system of beliefs based on a few words. While this is easy to do and sometimes feels justified it is wrong more often than not. Even if they identify as part of a group that you would like to categorize them into that they often don't hold all beliefs and you therefore misunderstand their argument. Putting them into a category makes the conversation worse because it biases your perception and means you don't focus on the actual argument presented before you.
6. **Quantify your uncertainty:** Especially while writing many indicators of uncertainty are left behind. A small sentence like "I'm not so sure about this" is often dropped or a specific intonation is undetectable for the reader where it would be present in e.g. a presentation. This means that written text often feels more confident than it actually is and therefore skews your perception of an issue. The thing that I would recommend and try to apply to my blog is to first identify how certain you are about a statement you want to write and then double-check whether this uncertainty can be identified from the text alone. People who do this very well include Scott Alexander from <a href='https://slatestarcodex.com/'>slatestarcodex</a> or <a href='https://www.youtube.com/c/AltShiftX/featured'>AltShiftX</a> in his YouTube videos.
7. **Don't feed the trolls:** Once you have concluded with high probability that someone is not taking you seriously, actively strawmans you or trolls you, it is, in my experience, best to stop engaging. A small amount of people, for some reason, thrives on misconstruing your perspective and seeing you suffer. However, I would be very careful with assigning someone the troll status because what seems intentional can also be a series of misunderstandings.
8. **Giving up:** Sometimes one finds oneself in a unsatisfactory deadlock within a discussion. It is not a situation where you can 'agree to disagree' on a specific premiss (e.g. to what extend markets are efficient) but rather a situation where you feel like one of you has to be right but you still have different opinions. Two of the go-to solutions for this deadlock are a) asking what conditions needed to be fulfilled to be persuaded or b) which metrics should be maximized. Note, that both of these questions also apply to you and your argument. These questions are designed to find a true answer not necessarily 'win' you an argument. An example of the first question in the context of the J.K. Rowling interview would be: "you currently believe that misogyny has never been worse in your lifetime. Which kind of evidence would convince you to believe otherwise?" and for the second: "Do we both agree that the most important question should be whether the long-term preferences of people with gender-dysphoria should be fulfilled (i.e. if it is a true and long-term desire they should get surgery and if it is short-term they should be more careful?) or do you think other goals, such as the perceived safety of women, is more important than that?". Asking these questions often also helps on a psychological level because what was perceived as a competition between you and the other person is suddenly reframed as a common endeavor to seek the truth. If all of that doesn't help you can give up ;).

### Who should be canceled and when?

After having discussed how you can improve your own contribution to the discourse we get to the final question: who should be canceled and when? Just to be clear - when I say canceling someone I mean one of two things. A 'soft' cancellation would be denying someone a platform, e.g. not inviting them to talks at your university or blocking their twitter account. A 'hard' cancellation includes the denial of a platform and additionally a clear public stance against them e.g. "Person X is a racist and if you invite them to this conference I will not attend". Everything that goes beyond that such as threatening personal messages, attacks on that person’s physical safety, etc. are both ineffective and immoral and I don't support them in any way. When thinking about canceling someone you should keep the following things in mind.

1. **Cancellation should be used carefully and selectively.** Even if well-intentioned they often take a life of their own and become incontrollable quickly. This <a href='https://www.youtube.com/watch?v=OjMPJVmXxV8&t=1s'>Video by ContraPoints</a> shows very clearly how fast this can happened and how hard it is to escape once you get caught. The psychological torture and pain that some canceled people have to go through are something that I would not even wish the people whose opinions I find most harmful.
2. **The cost of cancellation:** Especially when cancel culture is too trigger happy the cost should not be underestimated. Firstly, the people who are canceled or are afraid of being canceled in the future do not just disappear. They are often welcomed with open arms by right-wing populists and get radicalized in their ideas. This is exactly what happened to J.K. Rowling who, after her cancellation, endorsed rather conspiracy-like theories about gender harming the leftist cause more than before. Especially when the purity tests become too hard to pass for moderate left-wingers they can cause lots of harm. Canceling someone from the moderate end of your own political spectrum (e.g. Joe Biden) is the equivalent of shooting yourself in the foot. You lose and ally that broadly fought for your ideas just to a different extent and you give them incentives to actively denounce your cause. You potentially split the party into two camps and that can cost you elections in two-party systems (I want to express my admiration for AOC here who is pretty progressive but still manages to create unity when necessary for elections). The second harm is a culture where people are afraid of saying things that are potentially valuable. You could say that this is a well-targeted deterrent against people who are racist and sexist but I think that cancel culture has been used too loosely and therefore creates hot topics around things that should be open to discussion. While Yann LeCun could have phrased his original statements slightly better or emphasized that there is lots of research when it comes to bias in ML the response was clearly way over the top IMO. The result of such disproportional reactions is that the public sentiment is directed against a very important field within ML and many students are not willing to invest their time and effort in such a politically loaded field ("what if my PhD thesis gets canceled after 4 years of effort?"). Important progress is stopped at the point at which people don't feel psychologically or physically safe when publishing it. Peter Singer faced a huge public backlash from the left after saying that if you kill animals you should in principle also be OK with killing people who have very strong disabilities. His stance was clearly not contra handicapped people but pro animals and had he been canceled effectively huge amounts of progress for the animal rights movement would have been gone. Another example includes a publication of a paper on the relation between the availability of abortions and crime by the freakonimics co-hosts (see <a href='https://freakonomics.com/podcast/abortion/'>this episode</a>). They found that unwanted children (because abortion was not available) were more likely to have bad life-outcomes (education, income, and crime). They received death threats from the left and right. Some came from pro-life stance groups and others from people on the left who claimed that they did not have any respect for human life. This is clearly an unjustified and exaggerated claim. Freakonomics didn't argue to abort all people but rather to increase the availability of abortion clinics. I find it very positive that Singer and Levitt didn't back down because of the threads but I am sure that we have missed some important research because people are afraid of being misconstrued and canceled.
3. **What is the alternative?** There are other ways in which you can deal with people whose opinions you don't share than canceling them. I am generally a friend of public debate in the right setup - The better argument should win after all, right? A fair format should IMO include around equal time for all speakers a well-prepared moderator who asks follow-up questions and clarifications or a podcast format in-depth exploration of the speaker’s ideas. Bad formats include a setup where the deck is stacked against certain opinions (like in a Fox News 'debate') where everyone just shouts at each other or a format like the democratic primary 'debates' where every question was maximally loaded to create controversy and thereby viewers for CNN. These formats are harmful because they give you the illusion of information while they mostly satisfy your most basic instincts without actually informing you.

After all the contextualization and caveats I still want to point out some of the cases in which I think a cancellation is the correct response. These include: Milo Yiannopoulos, a right-wing polemicist who was mostly known for ridiculing leftist positions and creating controversy. He was banned by Twitter after publically insulting other public figures and isn't invited frequently anymore to speak at universities. He is an idiot who loves attention, the world has not lost any important opinions; Alex Jones, a right-wing conspiracy theorist who makes a living of inciting fear and selling products that are supposed to cure the fear. He, for example, claimed that coronavirus is very deadly and then tried to sell his patented cure for a large amount of money. The world would be better off if he didn't have as large of a platform. I would soft cancel some of the extremist members of the German right-wing party AfD (Alternative for Germany) e.g. Björn Höcke or Andreas Kalbitz who have repeatedly demonstrated that they are not willing to engage in any reasonable form of discourse and use their platform for dog-whistling or very explicit racism and homophobia. Other forms of curtailing free speech that I find positive is the banning of extremist subreddits like the <a href='https://en.wikipedia.org/wiki/Controversial_Reddit_communities#Incels'>r/incels</a> since they are a breeding ground for extremism at the worst and probably not very good for the mental health of all participants in the best case.

People that I would not cancel are Ben Shapiro and Jordan Peterson. Steve Bannon is somewhat of an edge case. While I disagree with most points of Ben Shapiro and Jordan Peterson I think their claims are sufficiently well-meaning and consistent that you could have a discussion with them. While they might not move a millimeter from their position it is still possible to convince a broader audience of the weird implications that some of their stances have or it is possible to point out the massive logical leaps they sometimes take.

## Summary and Conclusion

I think public discourse has become increasingly toxic over the last couple of years. Parts of this trend can be explained by Social media bubbles and human psychology and others by political polarization. To counteract these trends and a toxic culture in general I have provided a list of heuristics that can be used to improve individual discourse that will probably both improve your own experiences but also those of the people you communicate with. Lastly, I discussed the topic of cancelations where I argue that it should be used rarely and other alternatives should be explored first.

#### ***One last note***

If you have any feedback regarding anything (i.e. layout or opinions) please tell me in a constructive manner via your preferred means of communication.




