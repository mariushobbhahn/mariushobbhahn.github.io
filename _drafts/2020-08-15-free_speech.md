---
layout:     post
title:      "How much free speech is optimal?"
subtitle:   "What are some heuristics for good discourse?"
date:       2020-08-15 20:28:00
author:     "Marius Hobbhahn"
header-img: "img/header-imgs/free_speech.jpg"
category:   opinion
---

## **What is this post about?**

I have thought a lot about free speech lately. The events that influenced my thinking most were a long discussion/twitter war surrounding Yann LeCun about bias in Machine Learning that ultimately lead to a <a href='https://twitter.com/ylecun/status/1277372578231996424'>reduced Twitter presence</a> by him (click <a href='https://www.youtube.com/watch?v=n1SXlK5rhR8'>here</a> for an informative but biased summary) and the cancellation of J.K. Rowling due to her controversial <a href='https://www.jkrowling.com/opinions/j-k-rowling-writes-about-her-reasons-for-speaking-out-on-sex-and-gender-issues/'>stance on transgender issues</a>. In the case of Yann LeCun, I mostly thought about how the discourse could have been lead in a more productive and less toxic manner. I think that some of the criticisms were fair and others were not but the way in which the discourse was held was very suboptimal and Yann LeCun reducing his Twitter presence is a loss for the ML community.

In the case of J.K. Rowling, I was faced with different problems. While I agree with her on some problematic tendencies within parts of current online culture (e.g. the level of toxicity) I disagree with much of the content of her essay. She claims, for example, that "studies have consistently shown that between 60-90% of gender dysphoric teens will grow out of their dysphoria". There is a multitude of problems with these studies such as very small sample sizes, potentially biased researchers, potential confounders, and the ignorance of other studies on the same issues and I, therefore, think that this statement is at least misleading and should have been presented with less certainty and a more scientific contextualization. She also claims that "We’re living through the most misogynistic period I’ve experienced." which could be a statement about her lived experiences or a statement about online culture but feels more like a grander claim about society at large. I find this a bit confusing given that most indicators of gender equality have improved over the last 30 years (see e.g. the <a href='https://www.imf.org/external/datamapper/GII_TC@GD/gbtier_1/gbtier_2/gb_othersource'>Gender Inequality Index</a>). There are multiple other statements and sentiments that are wrong or misleading to the best of my current knowledge but some of the questions that she is raising are definitely worth asking. What if, for example, it actually is true that many people regret transitioning? What if the reasons for why they felt psychological stress about their gender are not tackled through a medical procedure but rather stem from other sources? What are they supposed to do when they have already gone through large parts of their transition and the decision is to some extend irreversibly? While she raises some interesting questions I think her answers are oversimplifying at best and rather harmful in the worst case. The conclusions that I draw from these questions are mostly that gender identity is a very complicated topic and we should support open-ended research without supporting a completely affirmative view (e.g. endorsing transition under all circumstances) or a "You will grow out of it" narrative that doesn't take those people seriously for whom transition is a viable and good option. The overarching questions that I asked myself in the context of J.K. Rowling’s essay were: a) How should you respond to someone who spreads wrong or easily misinterpretable content but has significantly more reach than the voices that raise concerns or try to engage in a correcting manner? And b) How do you stop an ideological drift after public criticism? After her cancellation, J.K. Rowling <a href='https://twitter.com/jk_rowling/status/1287015013513920512'>doubled down</a> on her claims and I can imagine that she will endorse even worse, conspiracy-like claims about gender and non-binary issues that might lead to more harm than the original essay. It wouldn't be the first time that there is an ideological right shift after someone gets canceled by the left.

Talking about free speech is always a bit weird for me because I don't subscribe to either of the classic ideological camps. Even though my cultural views are rather progressive I often don't like the strategy by which the goals are supposedly achieved (e.g. being very trigger happy with cancelation or restrictive about language in general). On the other hand, I don't consider myself a clear free speech advocate. I think it is completely fine to deny some people a platform or to cancel a person after a long history of racist or other problematic behavior. It is additionally weird for me because my go-to strategies of evidence-based policy or science are hardly applicable to questions regarding free speech since discourse often deals with very vague and hard to quantify concepts such as productivity (as in distinguishing good from bad ideas), inclusivity or agency.

What I will attempt in this post is to find a 'sweet spot' for free speech. While I originally assumed that free speech acts on a slider and could be turned up or down like a thermostat I don't believe this anymore. I now think that free speech is NOT on the one-dimensional spectrum but rather a collection of different individual behaviors and institutional rules that each lie on a spectrum of good and bad.
In this post, I want to identify different forms of behavior and general rules or heuristics that have a causal effect on the quality of discourse. I think these rules should attempt to maximize two metrics. The first metric is the productivity of the discourse, i.e. is it able to distill good ideas from bad ones and how high is the quality of the best opinions floating around (clearly this has a large degree of subjectivity attached but I haven't yet come across a more objective way for quantification). The second is inclusivity, i.e. how likely are people to engage in the discourse, are willing to voice non-conformist opinions, or feel excluded. I also want to clarify that when there is a trade-off to be made I would prioritize productivity because it seems more important to me that a good result is found than that everyone voices their opinion. A YouTube comments section, for example, is very inclusive in the sense that everyone feels like they can comment whatever they currently think but is very unproductive since most comments are bad, non-responsive, etc.

As always, if you think I have straw manned a specific argument, misrepresented a person or view, etc. please contact me.

## How did we get to the status quo?

Before we get into questions of how discourse should be designed we have to get a clearer picture of the status quo. I think there are three trends that have changed the discourse in the last couple of years that can mainly be attributed to its increased digitization and a shift to online platforms like Facebook, Twitter, and YouTube.

####1. **Social media and bubbles:**
Social media is run by for-profit corporations. They are responsible to their shareholders and their primary interest isn't to create optimal discourse but rather to maximize view time. With view time comes more ad-revenue and this is, therefore, what the algorithms are optimized for. Throw human psychology in the mix and you will get two rather unfortunate effects:

a) <a href=https://en.wikipedia.org/wiki/Confirmation_bias'>Confirmation bias</a> is a very strong human tendency to like information that confirm our previous beliefs and dislike information that refutes or weakens them. This means that the algorithms are created to or have learned to primarily present you with information that you broadly already believe in. This means that our current views are strengthened all the time but we are rarely confronted with evidence or arguments against our beliefs. Since you read even more stuff confirming your opinion and less refuting it you are also likely to become more radical in these beliefs.

b) To leave the comfort zone of your bubble a strong driver is needed. This often comes in the form of strong emotions such as anger and rage. Again, algorithms are designed to or have learned to create controversy to activate these strong emotions and actively promote posts that will spark a small internet war. Social media companies have been made aware of these trends and have acted to mitigate them (e.g. YouTube conspiracy theory rabbit holes are not as bad anymore as they used to be) but the overall trends still exist to the largest extent.

The consequences of this are clearly harmful. You either rarely interact with a view that you don't hold or when you interact with one you are fueled with rage ready to defend society against the barbarians from the other side.

####2. **Signaling and purity tests:**
Criticizing someone always has multiple components. On the one hand, you want to correct someone’s view and improve their knowledge. On the other hand, though, it is also about showing to others that you know better or that you stand on the right side of history. I think online discourse weakens the first component and emphasizes the second. If, for example, someone on Twitter says something racist there is nearly no point in writing a nuanced answer about how this could affect others and giving reasons for why they should change. The comment is too long and it will not get traction in the attention economy. Also, since you will likely not interact with that person ever again, there is no long-term benefit of your constructive engagement. Calling them a Nazi, however, will give you positive reinforcement. Since the algorithm will notify your own bubble of your valiant effort to defend the correct side of history you will get their likes and attention. Additionally, you gain social capital by being purer than everyone else. Calling someone a Nazi gives you more credit than calling someone a potential racist because it shows how pure you are. If you are willing to use the word Nazi so easily, you must hold yourself to high ethical standards or you would risk other people calling you a hypocrite. A similar mechanism is that it is more rewarding to attack people close to you. Calling Alex Jones a racist gives you no credit as it is obvious to your ingroup. So you will strike close to you, leading to more extreme positions, as it is dangerous to be close to the ideological boundary (see <a href='https://putanumonit.com/2020/06/18/fight-the-power/'>this post</a> for more details).

While these effects also existed before Twitter and Facebook existed, I think they were amplified through them. Online you will likely not interact with a person again and actually helping them is therefore not rewarding. In real life, you are more likely to meet them at work or school. Online you are rewarded by your own bubble but rarely notice the reactions of others. There are probably a lot of people looking at your comment and think "well that was a bit over the top. The person might be somewhat racist but calling them a Nazi is a bit drastic!". However, they either don't bother to comment or are not willing to defend someone who was already labeled a Nazi. In the real world, you would often see their facial reactions, or someone might actually pull you aside later and talk to you. Purist signaling is, therefore, not as rewarding in real life.

The problematic consequence of this is that criticism is not judged by whether it effectively changed someone’s mind for the better but rather by how much applause you get from your own peers. The fact that many people who are labeled as Nazis are welcomed with open arms by populist and conservative movements is not part of the consideration anymore. This argument obviously applies to the other side of the spectrum as well. Incorrectly labeling someone as a Communist will not increase your chances of persuading them either.

####3. **Political polarization:**
Many states around the world have seen an increase in political polarization. Its reasons are manifold and overlap with points above but I still want to explore a couple of them in the following. I think the primary reason is social media bubbles. If the majority of your voters are more radical and less understanding of other views than before, the politicians representing them are less likely to compromise. Meeting in the middle is more likely to be seen as a breach of trust and the respective politician as a traitor and compromises are therefore less likely to happen. Combine this with a broken electoral system such as the USA where it is more important to mobilize your base than to win over votes and you have a perfect recipe for gridlock. Politicians are really in a very precarious situation here. They first have to mobilize their base by telling them how evil the other side is to cater to their bubble, and then explain to them why they made a deal with the devil.

The second reason is that right-wing populist parties have been getting stronger in a lot of countries around the world. The reasons for that are complicated and include economic instability, a certain desire for identity, and a feeling of being left behind by the traditional establishment. However, they have shown much more competence than the established parties when it comes to social media and online discourse. Through this, they have successfully moved the Overton window for parts of society to the right and further split society in the middle.

Lastly, I think the availability of information combined with online bubbles has opened the possibility to strawman the shit out of your political opponents. Ben Shapiro choosing a young feminist that fulfills all the negative societal stereotypes (angry, uncontrolled, maybe overweight) to strawman their arguments and seemingly 'destroy' them has become the go-to characterization of feminism within the right-wing space. The left is equally guilty when it comes to this. There are dozens of people online that make a living by 'exposing' Trump voters by baiting them in dumb answers or selectively showing the most ridiculous ones. In both cases, the young feminist and the Trump supporter, are probably to a large extent victims of their socialization or brainwashed by Fox News and other media agencies but are portrayed as people with full agency choosing to support rather stupid positions. This implies that everyone can easily paint a scapegoat to strawman the other side. Instead of actually engaging with the arguments you can just say "look at this person and how dumb their arguments are".

The effects of political polarization can be seen in many places around the world but most drastically in the two-party system of the USA. Democrats and Republicans are in political gridlock and as long as Republicans control the Senate and Democrats the House not much legislation will actually be passed. Due to political polarization, legislation is seen more and more through the ideological lens and less as improving people’s lives independent of their political affiliation. Neither party can cooperate with the other because it is seen as "working with the devil" and politically punished instead of "compromising with others to improve society" and winning you votes. This means that important reform in education, health care, the prison system, and many other fields is lacking far behind. While there are clear ideological divides a large part of lawmaking and reform is just adapting to new circumstances and scientific discoveries that are independent of your ideology and would probably improve many lives. The ones who are harmed the most by this gridlock are, as always, the most vulnerable in society - those who are caught in a fucked up prison system, those who can't afford healthcare, and those who have terribly outdated education.

## What are the implications on free speech and discourse?

After having painted a rather grim picture of reality I want to discuss what individuals and society can do to counterbalance these problematic tendencies. Given that I think these trends are rather strong the countermeasures have to be too. Since the algorithms are often explicitly designed to or have learned to exploit our emotional drives and tendencies I think it is especially important to keep them in check or install measures to counterbalance them.

### What can institutions do?

I think institutions such as governments or international bodies can mostly mitigate the harms done through filter bubbles and other problematic trends created by social media. However, the exact mechanisms through which bubbles form and their effect have not yet been fully understood and governments are often, unfortunately, rather incompetent when it comes to technology. Therefore, we can't hope for the state to fix this one alone. Additionally, when it comes to public discourse the state is even more powerless for good reasons. It is not only hard to restrict and control the largest part of discourse but it is also not desirable. Since it is hard to actively censor people without restricting a lot of civil liberties the state would have to create an image of fear such that people self-censor as in authoritarian regimes. This is clearly too large of a price to pay for such a small benefit. In my opinion, the state should, therefore, prosecute the worst forms of hate speech or if people incite violence but everything softer than that is up to personal responsibility and norms of discourse.

### What does it mean for individual discourse?

The largest part of this post is therefore a collection of heuristics and rules that I think would lead to better discourse. If you think some of them don't make sense or I missed some please contact me.

1. **Check the setting:** I think the setting is a large determinant for what should be allowed to be said. In an academic setting, for example, I think nearly every hypothesis should be discussable. All participants voluntarily entered the discussion and it is sufficiently closed that it does not have larger ripple effects within society. In a more public setting, you should be more careful about the effects of your statements. I, for example, would not discuss my views on Antinatalism at the Christmas table when my cousin just had a baby but I think these views should be discussable in academia. If you feel like you have to present a more radical view in a public setting I would always make sure to announce that beforehand in some way to make sure people can opt-out. If people are forced to listen to you, e.g. because you are their professor, I would also advise to be a bit more careful. If they opted in knowing what the topic is I don't see any major problems. So the two axes on which I would evaluate the setting are closed vs. public and voluntarily vs. forced.
2. **Check your reach vs. expertise ratio:** If you have high reach but talk about a topic that you have little expertise in I would be rather careful. Even if J.K. Rowling just voiced her honest opinion she still is an idol for many younger people some of which are probably questioning their identity in some way or the other. If you publish an essay about such a controversial topic you better make sure that the evidence is watertight or you flag the difference between evidence and opinion more clearly. Jürgen Klopp, the trainer of Liverpool has actually given an <a href='https://www.youtube.com/watch?v=DkIZZCbxngQ'>surprisingly good answer</a> about the problem of reach vs. expertise when he was asked about his opinion on Corona.
3. **Assume good intentions:** Even though I know the pain of feeling like you are intentionally straw manned I think it is important to assume people act in good faith and only change that opinion when people have clearly demonstrated otherwise. There are so many reasons why people might make mistakes that are not driven by bad intentions. They might misgender someone by accident. Maybe it is their first confrontation with a transgender person and they are insecure about the situation as well. Maybe they have a different cultural background and their norms around discourse differ, e.g. they think something is normal that you find rude or the other way around. Maybe they are just less knowledgable than you are. A simple question such as 'How can you feel like a man when you were born a biological woman' might not be intensionally insensitive but just their first confrontation with the issue of transgender. There are many more reasons why something that looks like a bad-faith argument is actually not and we should a priori not assume it to be even if it costs us mental effort. I also want to stress that assuming good intentions sometimes requires mental fortitude. I, for example, probably heard the "If everyone was an EA wouldn't everyone in the West be poor and die" argument about 100 times by now. And while my brain is like "Ahhh I have explained this so often by now!!! When does the world finally understand???" I have to remind myself that for the person asking the question it is often the first time they learn about EA and this question seems to be a naturally arising first stress test of the principles underlying the movement’s core ideas. Remember that assuming good intentions is to a large extent just keeping your own bad habits in check.
4. **Constructive criticism:** I think that constructive criticism is the most important of all the heuristics laid out in this section. For criticism to be constructive it should a) not be blame seeking but solution-oriented, b) give an explicit and achievable improvement for the other person and c) focus on flexible things such as behavior and not static traits such as character. My personal experience is both that I am way more open to criticism when it is formulated in a constructive way but also that other people have been more open-minded when I phrased it in a constructive manner. Keep in mind though that even when your criticism is constructive it is often harder for a person to receive it in public than in private. This means that, especially when you want to give someone feedback on a sensitive topic or something that might be seen as embarrassing by the general public it is easier to approach them privately. I think a good example of a <a href='https://twitter.com/le_roux_nicolas/status/1275485736259792898'>considerate public response</a> in the whole Yann LeCun situation was given by Nicolas Le Roux.
5. **Try not to put in camps & ideologies:** I personally had many encounters where, after a couple of sentences, my brain went "Oh a Communist/Republican/Anti-vaxxer/Snob/Libertarian/Rationalist/EA/Debater/etc., here we go again" and tried to categorize them into some system of beliefs based on a few words. While this is easy to do and sometimes feels justified it is wrong more often than not. Even if they identify as part of a group that you would like to categorize them into, they often don't hold all beliefs and you, therefore, misunderstand their argument. Putting them into a category makes the conversation worse because it biases your perception and means you don't focus on the actual argument presented before you.
6. **Quantify your uncertainty:** Especially while writing many indicators of uncertainty are left behind. A small sentence like "I'm not so sure about this" is often dropped or a specific intonation is undetectable for the reader where it would be present in e.g. a presentation or conversation. This means that written text often feels more confident than it actually is and therefore skews your perception of an issue. The thing that I would recommend and try to apply to my blog is to first identify how certain you are about a statement you want to write and then double-check whether this uncertainty can be identified from the text alone. People who do this very well include Scott Alexander from <a href='https://slatestarcodex.com/'>slatestarcodex</a> or <a href='https://www.youtube.com/c/AltShiftX/featured'>AltShiftX</a> in his YouTube videos. A book that I can recommend for many reasons but especially for a consistently clear quantification of uncertainty is <a href='https://www.amazon.com/Precipice-Existential-Risk-Future-Humanity/dp/0316484911'>The Precipice</a> by Toby Ord.
7. **Don't feed the trolls:** Once you have concluded with high probability that someone is not taking you seriously, actively strawmaning you or trolls you, it is, in my experience, best to stop engaging. A small amount of people, for some reason, thrive on misconstruing your perspective and seeing you suffer. However, I would be very careful with assigning someone the troll status because what seems intentional can also be a series of misunderstandings.
8. **Giving up:** Sometimes we find ourselves in an unsatisfactory deadlock within a discussion. It is not a situation where you can 'agree to disagree' on a specific premiss (e.g. to what extend markets are efficient) but rather a situation where you feel like one of you has to be right but you still have different opinions. Two of the go-to solutions for this deadlock are a) asking what conditions needed to be fulfilled to be persuaded or b) which metrics should be maximized. Note, that both of these questions also apply to you and your argument. These questions are designed to find a true answer not necessarily 'win' you an argument. An example of the first question in the context of the J.K. Rowling interview would be: "you currently believe that misogyny has never been worse in your lifetime. Which kind of evidence would convince you to believe otherwise?" and for the second: "Do we both agree that the most important question should be whether the long-term preferences of people with gender-dysphoria should be fulfilled (i.e. if it is a true and long-term desire they should get surgery and if it is short-term they should be more careful?) or do you think other goals, such as the perceived safety of women, is more important than that?". Asking these questions often additionally helps on a psychological level because what was perceived as a competition between you and the other person is suddenly reframed as a common endeavor to seek the truth. If all of that doesn't help you can give up ;).

### Who should be canceled and when?

After having discussed how you can improve your own contribution to the discourse we get to the final question: who should be canceled and when? Just to be clear - when I say canceling someone I mean one of two things. A 'soft' cancellation would be denying someone a platform, e.g. not inviting them to talks at your university or Twitter blocking their account. A 'hard' cancellation includes the denial of a platform and additionally a clear public stance against them e.g. "Person X is a racist and if you invite them to this conference I will not attend". Everything that goes beyond that such as threatening personal messages, attacks on that person’s physical safety, etc. are both ineffective and immoral and I don't support them in any way. When thinking about canceling someone you should keep the following things in mind.

####1. **Cancellation should be used carefully and selectively.**
Even if well-intentioned they often take a life of their own and become uncontrollable quickly. This <a href='https://www.youtube.com/watch?v=OjMPJVmXxV8&t=1s'>Video by ContraPoints</a> shows very clearly how fast this can happen and how hard it is to escape once you get caught. The psychological torture and pain that some canceled people have to go through are something that I would not even wish the people whose opinions I find most harmful.

####2. **The cost of cancellation:**
Especially when cancel culture is too trigger happy the cost should not be underestimated. Firstly, the people who are canceled or are afraid of being canceled in the future do not just disappear. They are often welcomed with open arms by right-wing populists and get radicalized in their ideas. This is exactly what happened to J.K. Rowling who, after her cancellation, endorsed even less reasonable theories about gender harming the leftist cause more than before.

Especially when the purity tests become too hard to pass for moderate left-wingers they can cause lots of harm. Canceling someone from the moderate end of your own political spectrum (e.g. Joe Biden) is the equivalent of shooting yourself in the foot. You lose an ally that broadly fought for your ideas just to a different extent and you give them incentives to actively denounce your cause. You potentially split the party into two camps and that can cost you elections in two-party systems (I want to express my admiration for AOC here who is pretty progressive but still manages to create unity when necessary for elections).

The second harm is a culture where people are afraid of saying things that are potentially valuable. You could say that this is a well-targeted deterrent against people who are racist and sexist but I think that cancel culture has been used too loosely and therefore creates hot topics around things that should be open to discussion. While Yann LeCun could have phrased his original statements slightly better or emphasized that there is lots of research when it comes to bias in ML the response was way over the top in my opinion. The result of such disproportional reactions is that the public sentiment is directed against a very important field within ML and many students are not willing to invest their time and effort in such a politically loaded field ("what if my Ph.D. thesis gets canceled after 4 years of effort?"). Important progress is stopped at the point at which people don't feel psychologically or physically safe when publishing about it or when just being associated with a topic or person can pose a strong risk to your career prospects. Peter Singer faced a huge public backlash from the left after saying that if you kill animals you should, in principle, also be OK with killing people who have very strong disabilities. His stance was clearly not contra handicapped people but pro animals and had he been canceled effectively huge amounts of progress for the animal rights movement would have never existed. Another example includes a publication of a paper on the relation between the availability of abortions and crime by the Freakonomics co-hosts (see <a href='https://freakonomics.com/podcast/abortion/'>this episode</a>). They found that unwanted children (because abortion was not available) were more likely to have bad life-outcomes (education, income, and crime). They received death threats from the left and right. Some came from pro-life stance groups and others from people on the left who claimed that they did not have any respect for human life. This is clearly an unjustified and exaggerated claim. Freakonomics didn't argue to abort all people but rather to increase the availability of abortion clinics to prevent the negative outcomes of unwanted children for the parents, children, and society. I find it very positive that Singer and Freakonomics didn't back down because of the threads but I am sure that we have missed some important research because people are afraid of being misconstrued and canceled. Especially, because cancellation is such an undirected tool that doesn't follow predictable rules I would expect some people to be unwilling to publicly talk about important but sensitive topics. If a researcher found, for example, that a specific minority commits more crime on average, I could very well imagine that they would be unwilling to publish these findings because even if they added lots of additional analysis on the reasons for that statistic (discrimination, socio-economic background, politics) the headline could read "Researcher X shows that minority Y is more criminal" and the university that employes them might "have to let them go because they are a PR liability".

####3. **What is the alternative?**
There are other ways in which you can deal with people whose opinions you don't share than canceling them. I am generally a friend of public debate in the right setup - the better argument should win after all (at least over time), right? A fair format should in my opinion include around equal time for all speakers, a well-prepared moderator who asks follow-up questions, and clarifications or a podcast format in-depth exploration of the speaker’s ideas (such as <a href='http://rationallyspeakingpodcast.org/'>rationally speaking</a>). Bad formats include a setup where the deck is stacked against certain opinions (like in a Fox News "debate") where everyone just shouts at each other or a format like the democratic primary 'debates' where every question was maximally loaded to create controversy and thereby viewers for CNN. These formats are harmful because they give you the illusion of information while they mostly satisfy your most basic instincts without actually informing you.

After all the contextualization and caveats I still want to point out some of the cases in which I think a cancellation is the correct response. These include: Milo Yiannopoulos, a right-wing polemicist who was mostly known for ridiculing leftist positions and creating controversy. He was banned by Twitter after publically insulting other public figures and isn't invited frequently anymore to speak at universities. He is an idiot who loves attention, the world has not lost any important opinions; Alex Jones, a right-wing conspiracy theorist who makes a living of inciting fear and selling products that are supposed to cure the fear. He, for example, claimed that coronavirus is very deadly and then tried to sell his patented cure for a large amount of money. The world would be better off if he didn't have as large of a platform. I would soft cancel some of the extremist members of the German right-wing party AfD (Alternative for Germany) e.g. Björn Höcke or Andreas Kalbitz who have repeatedly demonstrated that they are not willing to engage in any reasonable form of discourse and use their platform for dog-whistling or very explicit racism and homophobia. My willingness to cancel is ideology-agnostic, i.e. if someone on the left end of the spectrum fulfills similar criteria as above I would endorse a cancellation. Another form of curtailing free speech that I find positive is the banning of extremist subreddits like the <a href='https://en.wikipedia.org/wiki/Controversial_Reddit_communities#Incels'>r/incels</a> since they are a breeding ground for extremism at the worst and probably not very good for the mental health of all participants in the best case.

People that I would not cancel include Ben Shapiro, Jordan Peterson, and J.K. Rowling. While I disagree with most points of Ben Shapiro and Jordan Peterson I think their claims are sufficiently well-meaning and consistent that you could have a discussion with them. While they might not move a millimeter from their position it is still possible to convince a broader audience of the weird implications that some of their stances have or it is possible to point out the massive logical leaps they sometimes take. I think that J.K. Rowling would be willing to consider possible criticism of the methodology of her scientific evidence and her argumentation (at least that was my impression in the essay). I, therefore, find it very unfortunate that the public response has been so extreme because it further closed the door on the opportunity of changing her mind.

## Summary and Conclusion

I think public discourse has become increasingly toxic over the last couple of years. Parts of this trend can be explained by social media bubbles and human psychology and others by political polarization. To counteract these trends and a toxic culture in general I have suggested a list of heuristics that can be used to improve individual discourse that will hopefully improve your own experiences but also those of the people you communicate with. Lastly, I discussed the topic of cancelations where I argue that it should be used rarely and other alternatives should be explored first.

I would like to thank Laurenz Hemmen for providing feedback and suggesting valuable content.

#### ***One last note***

If you have any feedback regarding anything (i.e. layout or opinions) please tell me in a constructive manner via your preferred means of communication.


