---
layout:     post
title:      "The reproducibility crisis in Machine Learning"
subtitle:   "TODO"
date:       2019-12-21 20:28:00
author:     "Marius Hobbhahn"
category:   ML_project
tags:       [machine learning, reproducibility]
---

## What is the purpose of this post?

I want to argue why a lot of the code and ideas that are produced in current Machine Learning (ML) research are not reproducible and why this is a problem. Specifically, I want to quantify through back of the envelope approximations how much value in time and financial capital is lost due to this.

To be clear, by not reproducible results I mean any of the following scenarios: A state-of-the-art (sota) results is claimed in the original paper but redoing the same experiment under similar circumstances does not yield the promised results; A method works on one or a small number of datasets but does not generalize to multiple others of the same kind without clear reasons; TODO: are there more?
I do not mean replicability, i.e. running the same code twice and getting different results. This is clearly also a problem in ML but one for another time. 

## Why do we have a reproducability crisis?

misaligned rewards
p-hacking
wrong assumptions




## Why is this a problem?

lost time and money: do back of the envelope computation based on the approximations of other research
It hits the most vulnurable the hardest.


## What can be done about this?

Discuss other approaches briefly and segway to reproducibleML journal


#### ***One last note***

If you have any feedback regarding anything (i.e. layout, code or opinions) I would be happy if you told me. But please do it in a constructive manner.



