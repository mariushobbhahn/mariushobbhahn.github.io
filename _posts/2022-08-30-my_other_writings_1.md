---
layout:     post
title:      "My other writings #1"
subtitle:   "Brief summary of some posts that are not on my blog"
date:       2022-08-30 20:28:00
author:     "Marius Hobbhahn"
header-img: "img/header-imgs/other_writings.png"
category:   opinion
tags:       [Miscellaneous]
---

## what is this post about?

Not all of my writing can be found here on my blog and over the recent past, I have written more and more on other platforms. Therefore, I decided to publish this summary of posts with links and short teasers.

I intend to write such an overview post whenever there is a decent number of posts to talk about.

## AI safety/alignment

1. The [AI safety starter pack](https://forum.effectivealtruism.org/posts/pbiGHk6AjRxdBPoD8/ai-safety-starter-pack) is a 5-minute overview for everyone who wants to start thinking about or working on AI safety/alignment.
2. In [What success looks like](https://forum.effectivealtruism.org/posts/AuRBKFnjABa6c6GzC/what-success-looks-like) we describe possible future scenarios in which AI leads to good possible futures and we collect and distill many variables about which factors might have a causal influence on decreasing risks from advanced AI. I think the post is a decent overview for people interested in high-level AI strategy or policy.
3. I have been working a lot with [EPOCH](https://www.lesswrong.com/posts/AJ6GHm5n6fBRJbMhq/announcing-epoch-a-research-organization-investigating-the), a new organization that models high-level trends in ML. Most prominently, we have investigated how much [compute is necessary to train large AI models](https://www.lesswrong.com/posts/XKtybmbjhC6mXDm5z/compute-trends-across-three-eras-of-machine-learning) and how the [price-performance of GPUs](https://www.lesswrong.com/posts/c6KFvQcZggQKZzxr9/trends-in-gpu-price-performance) has changed over time. There were also some smaller investigations into compute, that you can find on my [LW profile](https://www.lesswrong.com/users/marius-hobbhahn).
4. For our AI safety camp project, we polled a lot of ordinary people on moral questions related to AI alignment. Our results and their implications can be found in our post [Reflection mechanisms as an alignment target: a Survey](https://www.lesswrong.com/posts/XyBWkoaqfnuEyNWXi/reflection-mechanisms-as-an-alignment-target-a-survey-1).
5. I think Eliciting Latent Knowledge is a promising approach to alignment and have thus written a [summary/distillation](https://www.lesswrong.com/posts/rxoBY9CMkqDsHt25t/eliciting-latent-knowledge-elk-distillation-summary) for it.
6. Tom Lieberum and I have been playing around with GPT-3 to investigate how good its [causal understanding](https://www.lesswrong.com/posts/yZb5eFvDoaqB337X5/investigating-causal-understanding-in-llms) is.
7. I wrote some fortified essays on Metaculus for a challenge on transformative AI. The first essay looks at [take-off speeds of transformative AI](https://www.metaculus.com/notebooks/10508/will-transformative-ai-come-with-a-bang/), the second looks at how [accurate our predictions were over the last year](https://www.metaculus.com/notebooks/10624/how-good-were-our-ai-timeline-predictions-so-far/) and the third looks at predictions that [will resolve in the next five years](https://www.metaculus.com/notebooks/10655/the-next-five-years/).

<!---
## Effective altruism

1. We compiled a list of many possible [EA megaprojects](https://forum.effectivealtruism.org/posts/faezoENQwSTyw9iop/ea-megaprojects-continued)
2. We looked into the implications for EA and EA goals of the new [German government’s plans](https://forum.effectivealtruism.org/posts/8v3KyRozxvQEcCb2r/ea-analysis-of-the-german-coalition-agreement-2021-2025).
3. I wrote a brief post on an EA analogy called “[the train to crazy town](https://forum.effectivealtruism.org/posts/feejxTPvBJY2cfXRp/when-to-get-off-the-train-to-crazy-town)” which was originally coined by Ajeya Cotra on her 80K podcast appearance.
4. I asked a couple of questions (and sometimes suggested some answers), e.g. [where would we set up a new EA hub](https://forum.effectivealtruism.org/posts/d7bxPsKZ3TNnuaXaS/where-would-we-set-up-the-next-ea-hubs), [what is the right ratio between mentorship and direct work](https://forum.effectivealtruism.org/posts/wo7aQpkbwA9RJ8N29/what-is-the-right-ratio-between-mentorship-and-direct-work) or [how many EAs failed in high-risk, high-reward projects](https://forum.effectivealtruism.org/posts/JtE2srazz4Yu6NcuQ/how-many-eas-failed-in-high-risk-high-reward-projects).
-->

#### One last note

If you want to get informed about new posts you can [follow me on Twitter](https://twitter.com/MariusHobbhahn).

If you have any feedback regarding anything (i.e. layout or opinions) please tell me in a constructive manner via your preferred means of communication.
